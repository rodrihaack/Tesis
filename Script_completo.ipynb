{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41018d9",
   "metadata": {},
   "source": [
    "A continuación se muestra un esquema, a modo de resumen, de los cinco pasos que realiza el script\n",
    "\n",
    "\n",
    "\n",
    "![Cuadro](/home/S-PLUS/Pruebas_iDR4/Scripts/Cuadro.png \"Esquema de los cinco pasos del proceso de automatización\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5ad6c4",
   "metadata": {},
   "source": [
    "Importamos los paquetes necesarios para todo el codigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa86482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splusdata\n",
    "from astropy.io import fits\n",
    "import os\n",
    "import getpass\n",
    "import shutil\n",
    "import subprocess\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb17476",
   "metadata": {},
   "source": [
    "## ***PASO 1: Descargar campos a utilizar***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276662ea",
   "metadata": {},
   "source": [
    "El usuario deberá loguearse en splus.cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = input(prompt=\"Login: \")\n",
    "#password = getpass(\"Password: \")\n",
    "password = input(\"Password: \")\n",
    "conn = splusdata.connect(username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afd6060",
   "metadata": {},
   "source": [
    "Se eligen explícitamente en formato de lista los campos S-PLUS que se desean descargar, un ejemplo de cómo se nomenclan los campos SPLUS es: \"SPLUS-s24s31\", además se indica los filtro a utilizar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_campos = (\"SPLUS-s24s31\",\"SPLUS-s24s32\")\n",
    "lista_filtros = (\"F378\", \"F395\", \"F410\", \"F430\", \"F515\", \"F660\", \"F861\", \"U\", \"G\", \"R\", \"I\", \"Z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7ba391",
   "metadata": {},
   "source": [
    "Se crean una carpeta “Campos”. Para cada campo se crea una subcarpeta dentro de “Campos” con el nombre del campo y dentro de esta última una llamada “Imagenes Originales”, en la cuál se descargan 12 imágenes, una por cada filtro.\n",
    "\n",
    "Una vez obtenida una imagen, se revisa que el header sea el completo y no el breve. Luego de la revisión, se guarda la imagen correspondiente a un filtro y se prosigue con el  siguiente. Al haber culminado de descargar las 12 imágenes para un cierto campo, se pasa a realizar el mismo proceso para el siguiente campo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90becb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for campo in lista_campos:\n",
    "    print(\"Procesando:\", campo)\n",
    "    os.makedirs(f'Campos/{campo}/Imagenes_originales/', exist_ok=True)\n",
    "    for filtro in lista_filtros:\n",
    "        print(\"Procesando:\", campo, filtro)\n",
    "        hdu = conn.get_field(campo, filtro)\n",
    "        hdu.writeto(f\"Campos/{campo}/Imagenes_originales/{campo}_{filtro}_swp.fits\", overwrite=True)\n",
    "        hdul1 = fits.open(f\"Campos/{campo}/Imagenes_originales/{campo}_{filtro}_swp.fits\")\n",
    "        hdr2 = hdul1[1].header\n",
    "        print(hdr2) # Aquí se revisa el header\n",
    "        hdul1_data = fits.getdata(f\"Campos/{campo}/Imagenes_originales/{campo}_{filtro}_swp.fits\")\n",
    "        fits.writeto(f\"Campos/{campo}/Imagenes_originales/{campo}_{filtro}_swp.fits\", data = hdul1_data, header = hdr2, overwrite = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa14bcb4",
   "metadata": {},
   "source": [
    "## ***PASO 2: Imágen Suma***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f5bbc9",
   "metadata": {},
   "source": [
    "En este paso para cada campo se crea una carpeta “Imagenes” en paralelo a “Imágenes Originales”, se copian las 12 imágenes originales descargadas a la nueva carpeta, esto se realiza para tener un respaldo. Para realizar esto se utilizan los paquetes “os” y “shutil”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b96db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for campo in lista_campos:\n",
    "    print(\"Procesando:\", campo)\n",
    "    filtros_de_cada_campo = os.listdir(f'Campos/{campo}/Imagenes_originales')\n",
    "    os.makedirs(f'Campos/{campo}/Imagenes/', exist_ok=True)\n",
    "    for filtro in filtros_de_cada_campo:\n",
    "        dir_entrada = f'Campos/{campo}/Imagenes_originales/{filtro}'\n",
    "        shutil.copy(dir_entrada, f'Campos/{campo}/Imagenes/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0c79d2",
   "metadata": {},
   "source": [
    "\n",
    "Luego para cada campo se lee la data (arreglo de pixeles) de las imágenes correspondientes a los filtros: “G”, “R”, “I” y “Z”. Como tenemos 4 arreglos podemos sumarlos y así generar una imagen suma. La suma es una suma simple no ponderada, es decir, los 4 filtros tienen el mismo peso. Mismo procedimiento que realiza la colaboración S-PLUS.\n",
    "\n",
    "Al filtro “I” además de leerle la data se le lee el header, se lo duplica y se le modifican los siguientes parámetros: FILTER y FILENAME.\n",
    "\n",
    "Este Header modificado es asignado como header de la imagen suma. La cual es guardada en paralelo al resto de los 12 filtro, es decir, en la carpeta “Imagenes”. Se realiza el mismo proceso para todos los restantes campos.\n",
    "\n",
    "La imagen suma generada será utilizada para correr SExtractor, cumpliendo la función de se la imagen de medición, osea, la referencia de donde se harán las extracciones para cada filtro. La principal motivación de construir una imagen suma es poder aumentar la señal e intentar no perder objetos débiles al momento de la medición.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for campo in lista_campos:\n",
    "    print(\"Generando imagen suma del campo:\", campo)\n",
    "    img_i = fits.getdata(f'Campos/{campo}/Imagenes/{campo}_I_swp.fits')\n",
    "    img_r = fits.getdata(f'Campos/{campo}/Imagenes/{campo}_R_swp.fits')\n",
    "    img_g = fits.getdata(f'Campos/{campo}/Imagenes/{campo}_G_swp.fits')\n",
    "    img_z = fits.getdata(f'Campos/{campo}/Imagenes/{campo}_Z_swp.fits') \n",
    "    suma_filtros = img_i + img_r + img_g + img_z # imagen compuesta de la suma de los filtros\n",
    "    hdul1 = fits.open(f'Campos/{campo}/Imagenes/{campo}_I_swp.fits')\n",
    "    hdr2 = hdul1[0].header # lectura del header del filtro I \n",
    "    hdr2.set('FILTER', 'G+R+I+Z') # cambio del filtro en el header de la imagen compuesta\n",
    "    hdr2.set('FILENAME', f'Campos/{campo}/Imagenes/{campo}_suma.fits') # cambio del nombre de archivo en la imagen compuesta\n",
    "    print(\"SE IMPRIMIRA EL HEADER\", hdr2)\n",
    "    fits.writeto(f'Campos/{campo}/Imagenes/{campo}_suma.fits', data = suma_filtros, header = hdr2, overwrite = True) # guardado de la data más el header con todas las modificaciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf2f39a",
   "metadata": {},
   "source": [
    "## ***PASO 3: Lectura y selección de parámetros***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a279f3",
   "metadata": {},
   "source": [
    "Aquí, el código comienza recorriendo un campo por uno y dentro de cada uno de ellos construye un lista con las 12 imágenes de filtros y logra identificar y apartar a la imagen suma. Crea una carpeta “Catalogos/{run}” paralela a “Imagenes” e “Imagenes Originales”.\n",
    "\n",
    "Se lee por completo una tabla con los puntos de cero (ZP) previamente descargada y proporcionada por splus.cloud. Esta tabla contiene un campo por cada fila, y en las columnas el ZP correspondiente a cada filtro.\n",
    "\n",
    "Se empieza a recorrer, dentro de un campo fijo, un filtro por uno. Por un lado, se lee el nombre del filtro, se lo identifica, y se le asigna el respectivo valor de zeropoint vinculado con la tabla. Por otro lado, a dicho filtro se le sustraen del header los siguientes parámetros:\n",
    "\n",
    "SATURATE , GAIN y SEEING_FWHM\n",
    "\n",
    "Esto se realiza con la intención de hacer la medición de SExtractor bajo los valores, de dichos parámetros, con los que fue tomada la imagen. Cabe mencionar, que los 3 parámetros varían según el filtro aún siendo imágenes del mismo campo. \n",
    "\n",
    "El presente paso y el siguiente estan dentro de la misma celda. Comparten ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3cf127",
   "metadata": {},
   "source": [
    "## ***PASO 4: Archivos de configuración y ejecuciones de SExtractor***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a2130",
   "metadata": {},
   "source": [
    "En este paso, primero que nada se elige el archivo de configuración con el que se realizarán las ejecuciones de SExtractor. Los archivos de configuración incluyen información sobre los parámetros que se desean que aparezcan en el catálogo de salida, información sobre parámetros para guiar la detección y extracción, información sobre la imagen (fotometría y separación estrella/galaxia), información para realizar la estimación del background y por último sobre las imágenes de chequeo.\n",
    "\n",
    "Una vez elegido el archivo de configuración y recordando que se está recorriendo filtro por filtro dentro de un cierto campo y que por cada campo se tiene identificado a la imagen suma. Se genera una dirección dual, directorio que incluye tanto a la imagen de detección como a la de medición. La de detección será la imagen suma y será la misma para todos los filtros del campo, mientras que la imagen de medición irá variando filtro a filtro. Para ejecutar SExtractor desde Python se utilizo el paquete “subprocess”, el cuál interactúa con una terminal bash para justamente correr SExtractor. \n",
    "\n",
    "Se elige el nombre con el que se identificará la corrida, el cúal es asignado a \"run\".\n",
    "\n",
    "La salida de esta ejecución genera un catálogo por cada filtro que es guardado en  “/Campos/{campo}/Catalogos/{run}/cat_{filtro}. Es decir, en esta instancia, por campo habrá 12 catálogos.\n",
    "\n",
    "Además en estas PASO se obtienen las imágenes de chequeo, CHECK_IMAGES. Para ello simplemente se realiza una sola ejecución de SExtractor en modo simple, es decir, se detecta y se mide sobre la misma imagen. Y la imagen utilizada para realizar dicho proceso, es la imágen suma correspondiente a cada campo. \n",
    "\n",
    "Donde luego de la ejecución de SExtractor, se crea un directorio “Imagenes_check” en paralelo a la carpetas “Campos” y dentro de es carpeta, mueve la imagen de chequeo correspondiente al campo a una subcarpeta “Imagenes_check/{run}”. Por lo tanto, las imágenes de chequeo de todos los campos quedan guardadas diferenciadas por {run}.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#puntos_cero = open('Archivos_de_Configuracion/iDR4_zero-points.csv', 'r', encoding = \"utf8\")\n",
    "#puntos_cero_reader = csv.reader(puntos_cero, delimiter = ',')\n",
    "#header = next(puntos_cero) \n",
    "archivo_configuracion = input(prompt=\"Ingrese el nombre del archivo de configuración a utilizar: \")\n",
    "dir_entrada_configuracion = f'Archivos_de_Configuracion/{archivo_configuracion}'\n",
    "run = input(prompt=\"Ingrese el nombre con el que identificará las ejecuciones: \")\n",
    "for campo in lista_campos:\n",
    "    filtros_de_cada_campo_aux = os.listdir(f'Campos/{campo}/Imagenes')\n",
    "    filtros_de_cada_campo = list(filter(lambda filtro: (not filtro.count('.fz')) and (not filtro.count('suma')), filtros_de_cada_campo_aux)) \n",
    "    lista_filtro_suma = list(filter(lambda filtro: filtro.count('suma'), filtros_de_cada_campo_aux))\n",
    "    filtro_suma = lista_filtro_suma[0]\n",
    "    dir_entrada_suma = f'Campos/{campo}/Imagenes/{filtro_suma}'\n",
    "    os.makedirs(f\"Campos/{campo}/Catalogos/{run}/\", exist_ok=True)            \n",
    "    print(\"Procesando\", campo)\n",
    "    puntos_cero = open('Archivos_de_Configuracion//iDR4_zero-points.csv', 'r', encoding = \"utf8\")\n",
    "    puntos_cero_reader = csv.reader(puntos_cero, delimiter = ',')\n",
    "    header = next(puntos_cero)\n",
    "    for row in puntos_cero_reader:\n",
    "            if row[0] == campo:\n",
    "                for filtro in filtros_de_cada_campo:\n",
    "                    dir_salida = f'Campos/{campo}/Catalogos/{run}/cat_{filtro}'\n",
    "                    isExist = os.path.exists(dir_salida)\n",
    "                    if not isExist:\n",
    "                        if filtro.count('U_swp.fits'):\n",
    "                            zeropoint = row[3]\n",
    "                            print(\"Campo:\", campo, \"Filtro:\", filtro, \"Punto de cero:\", zeropoint)\n",
    "                        elif filtro.count('F378_swp.fits'):\n",
    "                            zeropoint = row[4]\n",
    "                            print(\"Campo:\", campo, \"Filtro:\", filtro, \"Punto de cero:\", zeropoint)\n",
    "                        elif filtro.count('F395_swp.fits'):\n",
    "                            zeropoint = row[5]\n",
    "                            print(\"Campo:\", campo, \"Filtro:\", filtro, \"Punto de cero:\", zeropoint)\n",
    "                        elif filtro.count('F410_swp.fits'):\n",
    "                            zeropoint = row[6]\n",
    "                            print(\"Campo:\", campo, \"Filtro:\", filtro, \"Punto de cero:\", zeropoint)\n",
    "                        elif filtro.count('F430_swp.fits'):\n",
    "                            zeropoint = row[7]\n",
    "                            print(\"Campo:\", campo, \"Filtro:\", filtro, \"Punto de cero:\", zeropoint)\n",
    "                        elif filtro.count('G_swp.fits'):\n",
    "                            zeropoint = row[8]\n",
    "                            print(\"Campo:\", campo, \"Filtro:\", filtro, \"Punto de cero:\", zeropoint)\n",
    "                        elif filtro.count('F515_swp.fits'):\n",
    "                            zeropoint = row[9]\n",
    "                            print(\"Campo:\", campo, \"Filtro:\", filtro, \"Punto de cero:\", zeropoint)\n",
    "                        elif filtro.count('R_swp.fits'):\n",
    "                            zeropoint = row[10]\n",
    "                            print(\"Campo:\", campo, \"Filtro:\", filtro, \"Punto de cero:\", zeropoint)\n",
    "                        elif filtro.count('F660_swp.fits'):\n",
    "                            zeropoint = row[11]\n",
    "                            print(\"Campo:\", campo, \"Filtro:\", filtro, \"Punto de cero:\", zeropoint)\n",
    "                        elif filtro.count('I_swp.fits'):\n",
    "                            zeropoint = row[12]\n",
    "                            print(\"Campo:\", campo, \"Filtro:\", filtro, \"Punto de cero:\", zeropoint)\n",
    "                        elif filtro.count('F861_swp.fits'):\n",
    "                            zeropoint = row[13]\n",
    "                            print(\"Campo:\", campo, \"Filtro:\", filtro, \"Punto de cero:\", zeropoint)\n",
    "                        elif filtro.count('Z_swp.fits'):\n",
    "                            zeropoint = row[14]\n",
    "                            print(\"Campo:\", campo, \"Filtro:\", filtro, \"Punto de cero:\", zeropoint)\n",
    "                        dir_entrada = f'Campos/{campo}/Imagenes/{filtro}'\n",
    "                        dir_salida = f'Campos/{campo}/Catalogos/{run}/cat_{filtro}' \n",
    "                        hdul = fits.open(dir_entrada)\n",
    "                        hdr = hdul[0].header\n",
    "                        SATURATE = hdr['SATURATE']\n",
    "                        GAIN = hdr['GAIN']   \n",
    "                        SEEING_FWHM = hdr['HIERARCH OAJ PRO FWHMSEXT']\n",
    "                        dir_dual = f'\"Campos/{campo}/Imagenes/{filtro_suma}\",\"Campos/{campo}/Imagenes/{filtro}\"'\n",
    "                        print(\"Generando catalogo\", filtro)\n",
    "                        subprocess.run([\"sextractor\", dir_dual, \"-c\", f\"{dir_entrada_configuracion}\", f\"-CATALOG_NAME {dir_salida}\", f\"-GAIN {GAIN}\", f\"-SEEING_FWHM {SEEING_FWHM}\", f\"-SATUR_LEVEL {SATURATE}\", f\"-MAG_ZEROPOINT {zeropoint}\"])\n",
    "                        os.makedirs(f\"Campos/{campo}/Imagenes_check/\", exist_ok=True)\n",
    "                        dir_salida_check_aux = f'{campo}_{run}.fits'\n",
    "                        dir_check = re.sub(\"SPLUS-\",\"\",dir_salida_check_aux)\n",
    "                        print(\"GENERANDO IMAGEN CHECK DE:\", dir_check)\n",
    "                        subprocess.run([\"sextractor\", dir_entrada_suma, \"-c\", f\"{dir_entrada_configuracion}\", \"-CATALOG_NAME\", \"../cat_2.fits\", \"-CHECKIMAGE_TYPE\", \"APERTURES\", \"-CHECKIMAGE_NAME\", f\"../{dir_check}\"])\n",
    "                        os.makedirs(f\"../Imagenes_check/{run}/\", exist_ok=True)\n",
    "                        shutil.move(f\"../{dir_check}\", f\"../Imagenes_check/{run}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e71ba8",
   "metadata": {},
   "source": [
    "## ***PASO 5: Modificación y fusión de catálogos***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18306a3f",
   "metadata": {},
   "source": [
    "En esta instancia se realiza el proceso de estandarización, union y fusión de los catálogos. Se comienza nuevamente recorriendo campo por campo, filtro por filtro. Se crea un directorio dentro de la carpeta “/Campos/{campo}/Catalogos/” llamado “Catalogos_modificados” donde se copian los 12 catalogos correspondientes a sus respectivos filtros que fueron generados en el PASO 4 y que se encuentran en “/Campos/{campo}/Catalogos/{run}/”.\n",
    "\n",
    "A estas copias de los catálogos se le realizarán las siguientes modificaciones. Por un lado, se despliegan todas las columnas que sean arreglos. Este es el caso de: las MAG_APER, sus errores, FLUX_APER, sus errores y también de los FLUX_RADIUS.\n",
    "\n",
    "Luego a esa primera modificación se le suma una modificación en el nombre de ciertas columnas. Esto se realiza buscando, por un lado, estandarizar los nombres para que coincidan con los catalogos S-PLUS y, por otro lado, para agregarles el nombre del filtro explícitamente en las columnas que difieren entre catálogos de distintos filtros dentro del mismo campo. \n",
    "\n",
    "Donde por primera vez aquí se utiliza el paquete “pandas” para leer y modificar el catálogo como un DataFrame. Nuevamente este catálogo modificado sobrescribe al anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "for campo in lista_campos:\n",
    "    print(\"Procesando:\",campo)\n",
    "    lista_catalogos_internos_aux = os.listdir(f'Campos/{campo}/Catalogos/{run}')\n",
    "    lista_catalogos_internos = list(map(lambda cat: re.sub(\".fits\",\"\",cat), lista_catalogos_internos_aux))\n",
    "    os.makedirs(f\"Campos/{campo}/Catalogos/Catalogos_modificados/{run}/\", exist_ok=True)\n",
    "    for catalogo in lista_catalogos_internos:\n",
    "        print(\"Generando:\",catalogo)\n",
    "        if catalogo.count('U_swp'):\n",
    "            filtro = \"U\"\n",
    "        elif catalogo.count('F378_swp'):\n",
    "            filtro = \"F378\"\n",
    "        elif catalogo.count('F395_swp'):\n",
    "            filtro = \"F395\"\n",
    "        elif catalogo.count('F410_swp'):\n",
    "            filtro = \"F410\"\n",
    "        elif catalogo.count('F430_swp'):\n",
    "            filtro = \"F430\"\n",
    "        elif catalogo.count('G_swp'):\n",
    "            filtro = \"G\"\n",
    "        elif catalogo.count('F515_swp'):\n",
    "            filtro = \"F515\"\n",
    "        elif catalogo.count('R_swp'):\n",
    "            filtro = \"R\"\n",
    "        elif catalogo.count('F660_swp'):\n",
    "            filtro = \"F660\"\n",
    "        elif catalogo.count('I_swp'):\n",
    "            filtro = \"I\"\n",
    "        elif catalogo.count('F861_swp'):\n",
    "            filtro = \"F861\"\n",
    "        elif catalogo.count('Z_swp'):\n",
    "            filtro = \"Z\" \n",
    "        subprocess.run([\"stilts\", \"tcopy\", f\"Campos/{campo}/Catalogos/{run}/{catalogo}.fits\", f\"Campos/{campo}/Catalogos/Catalogos_modificados/{run}/{catalogo}.fits\", \"ifmt=fits\", \"ofmt=fits\"])\n",
    "        dir_1 = f\"Campos/{campo}/Catalogos/Catalogos_modificados/{run}/{catalogo}.fits\"\n",
    "        subprocess.run([\"stilts\", \"tpipe\", f'in={dir_1}',\"cmd= explodeall\", f'out={dir_1}'])\n",
    "        dat = Table.read(f\"Campos/{campo}/Catalogos/Catalogos_modificados/{run}/{catalogo}.fits\")\n",
    "        df = dat.to_pandas()\n",
    "        df.rename(columns={'ALPHA_J2000':'RA', 'DELTA_J2000':'DEC', 'FLUX_AUTO':f'FLUX_AUTO_{filtro}','FLUXERR_AUTO':f'FLUXERR_AUTO_{filtro}','MAG_AUTO':f'{filtro}_AUTO','MAGERR_AUTO':f'e_{filtro}_AUTO','FLUX_ISO':f'FLUX_ISO_{filtro}','FLUXERR_ISO':f'FLUXERR_ISO_{filtro}','MAG_ISO':f'{filtro}_ISO','MAGERR_ISO':f'e_{filtro}_ISO','FLUX_PETRO':f'FLUX_PETRO_{filtro}','FLUXERR_PETRO':f'FLUXERR_PETRO_{filtro}','MAG_PETRO':f'{filtro}_PETRO','MAGERR_PETRO':f'e_{filtro}_PETRO','MAG_APER_1':f'{filtro}_APER_3','MAG_APER_2':f'{filtro}_APER_6','MAGERR_APER_1':f'e_{filtro}_APER_3','MAGERR_APER_2':f'e_{filtro}_APER_6','FLUX_APER_1':f'FLUX_APER_3_{filtro}','FLUX_APER_2':f'FLUX_APER_6_{filtro}','FLUXERR_APER_1':f'FLUXERR_APER_3_{filtro}','FLUXERR_APER_2':f'FLUXERR_APER_6_{filtro}','FLAGS':f'FLAGS_{filtro}', 'FWHM_IMAGE':f'FWHM_IMAGE_{filtro}', 'FWHM_WORLD':f'FWHM_WORLD_{filtro}', 'ISOAREA_IMAGE':f'ISOAREA_IMAGE_{filtro}', 'ISOAREA_WORLD':f'ISOAREA_WORLD_{filtro}', 'KRON_RADIUS':f'KRON_RADIUS_{filtro}', 'PETRO_RADIUS':f'PETRO_RADIUS_{filtro}', 'FLUX_RADIUS_1':f'FLUX_RADIUS_20_{filtro}', 'FLUX_RADIUS_2':f'FLUX_RADIUS_50_{filtro}', 'FLUX_RADIUS_3':f'FLUX_RADIUS_70_{filtro}', 'FLUX_RADIUS_4':f'FLUX_RADIUS_90_{filtro}', 'FLUX_MAX':f'FLUX_MAX_{filtro}', 'SNR_WIN':f'SNR_WIN_{filtro}', 'MU_THRESHOLD':f'MU_THRESHOLD_{filtro}', 'THRESHOLD':f'THRESHOLD_{filtro}', 'MU_MAX':f'MU_MAX_{filtro}', 'CLASS_STAR':f'CLASS_STAR_{filtro}', 'BACKGROUND':f'BACKGROUND_{filtro}'},inplace=True)\n",
    "        t = Table.from_pandas(df)\n",
    "        t.write(f\"Campos/{campo}/Catalogos/Catalogos_modificados/{run}/{catalogo}.fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd895bed",
   "metadata": {},
   "source": [
    "Posterior a este proceso, se procede a juntar todos los catálogos modificados de un mismo campo en solo un catálogo por campo. Para ello, utilizando otra vez “pandas”, se crea una lista de los 12 DataFrames correspondientes a los 12 catálogos modificados a fusionar. Antes de hacer la fusión de uno los DataFrames se extrae la información de las primeras columnas, es decir, se separa la información común a todos los catalogos, es decir, la astrometría y geometría.\n",
    "\n",
    "Luego sobre la lista de DataFrames se realiza la fusión, bajo un matcheo doble en RA y DEC. Se agregan como primeras columnas “ID” y “Filter”, se ordena según RA y se le da un formato específico a los nombres de los objetos en la columna ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df028f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for campo in lista_campos:\n",
    "    print(\"Procesando:\",campo)\n",
    "    lista_catalogos_aux = os.listdir(f'Campos/{campo}/Catalogos/Catalogos_modificados/{run}')\n",
    "    for catalogo in lista_catalogos_aux:\n",
    "        if catalogo.count('U_swp'):\n",
    "            filtro_U = catalogo\n",
    "        elif catalogo.count('F378_swp'):\n",
    "            filtro_F378 = catalogo\n",
    "        elif catalogo.count('F395_swp'):\n",
    "            filtro_F395 = catalogo\n",
    "        elif catalogo.count('F410_swp'):\n",
    "            filtro_F410 = catalogo\n",
    "        elif catalogo.count('F430_swp'):\n",
    "            filtro_F430 = catalogo\n",
    "        elif catalogo.count('G_swp'):\n",
    "            filtro_G = catalogo\n",
    "        elif catalogo.count('F515_swp'):\n",
    "            filtro_F515 = catalogo\n",
    "        elif catalogo.count('R_swp'):\n",
    "            filtro_R = catalogo\n",
    "        elif catalogo.count('F660_swp'):\n",
    "            filtro_F660 = catalogo\n",
    "        elif catalogo.count('I_swp'):\n",
    "            filtro_I = catalogo\n",
    "        elif catalogo.count('F861_swp'):\n",
    "            filtro_F861 = catalogo\n",
    "        elif catalogo.count('Z_swp'):\n",
    "            filtro_Z = catalogo\n",
    "    lista_catalogos = [filtro_U, filtro_F378, filtro_F395, filtro_F410, filtro_F430, filtro_G, filtro_F515, filtro_R, filtro_F660, filtro_I, filtro_F861, filtro_Z]\n",
    "    data_frames = []\n",
    "    df_1_aux = lista_catalogos[0]\n",
    "    lector = Table.read(f'Campos/{campo}/Catalogos/Catalogos_modificados/{run}/{df_1_aux}')\n",
    "    df_1 = lector.to_pandas()\n",
    "    df_1.drop(df_1.iloc[:, 21:-1], inplace=True, axis='columns')\n",
    "    data_frames.append(df_1)\n",
    "    for catalogo in lista_catalogos:\n",
    "        print(\"Procesando:\", catalogo)         \n",
    "        lector = Table.read(f'Campos/{campo}/Catalogos/Catalogos_modificados/{run}/{catalogo}')\n",
    "        df = lector.to_pandas()\n",
    "        df.drop(df.iloc[:, 0:1], inplace=True, axis='columns')\n",
    "        df.drop(df.iloc[:, 2:20], inplace=True, axis='columns')\n",
    "        data_frames.append(df)\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right, on=['RA','DEC'], how='inner', copy=False), data_frames)\n",
    "    lista_number = df_merged.NUMBER.to_list()\n",
    "    df_merged.drop(columns ={'BACKGROUND_U_x'}, inplace=True)\n",
    "    df_merged.drop(columns ={'NUMBER'}, inplace=True)\n",
    "    df_merged.rename(columns={'BACKGROUND_U_y':'BACKGROUND_U'},inplace=True)\n",
    "    df_merged = df_merged.sort_values('RA',ascending=True)\n",
    "    df_merged.insert(0,\"ID\",lista_number,True)\n",
    "    df_merged.insert(1, \"Field\", f\"{campo}\", allow_duplicates=False)\n",
    "    df_merged = df_merged.sort_values('RA',ascending=True)\n",
    "    for ID in range(len(df_merged.ID)+1):\n",
    "        df_merged.ID = df_merged.ID.replace({ID: f\"iDR4_FORNAX_RUN1_{campo}.{str(ID).rjust(5, '0')}\"})\n",
    "    t = Table.from_pandas(df_merged)\n",
    "    t.write(f'Campos/{campo}/Catalogos/cat_{campo}_12_filtros_{run}.fits', overwrite=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a87b6b",
   "metadata": {},
   "source": [
    "Agregar CONCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a0f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'Catalogos_finales',  exist_ok=True)\n",
    "data_frames = []\n",
    "lista_catalogos_a_concat = [] \n",
    "for campo in lista_campos:\n",
    "    print(\"Procesando:\", campo)\n",
    "    archivos_campo_aux = os.listdir(f'Campos/{campo}/Catalogos')\n",
    "    lista_catalogo_campo = list(filter(lambda filtro: filtro.count(f'_{run}.fits'), archivos_campo_aux))\n",
    "    catalogo_campo_aux = lista_catalogo_campo[0]\n",
    "    catalogo_campo = f'Campos/{campo}/Catalogos/' + catalogo_campo_aux\n",
    "    print(\"Agregando:\", catalogo_campo)\n",
    "    lista_catalogos_a_concat.append(catalogo_campo)\n",
    "    lector = Table.read(catalogo_campo)\n",
    "    df = lector.to_pandas()\n",
    "    data_frames.append(df)\n",
    "data_frames_1 = data_frames[0:20]\n",
    "data_frames_2 = data_frames[20:40]\n",
    "data_frames_3 = data_frames[40:60]\n",
    "data_frames_4 = data_frames[60:80]\n",
    "data_frames_5 = data_frames[80:99]   \n",
    "\n",
    "print(\"Realizando la concatenación_1\")\n",
    "df_concat = pd.concat(data_frames_1)\n",
    "print(\"Paso la concatenación_1\")\n",
    "df_concat = df_concat.sort_values('ID',ascending=True)\n",
    "t = Table.from_pandas(df_concat)\n",
    "t.write(f'Catalogos_finales/Catalogos_explode/catalogo_final_{run}_1.fits', overwrite=True)\n",
    "\n",
    "print(\"Realizando la concatenación_2\")\n",
    "df_concat = pd.concat(data_frames_2)\n",
    "print(\"Paso la concatenación_2\")\n",
    "df_concat = df_concat.sort_values('ID',ascending=True)\n",
    "t = Table.from_pandas(df_concat)\n",
    "t.write(f'Catalogos_finales/Catalogos_explode/catalogo_final_{run}_2.fits', overwrite=True)\n",
    "\n",
    "print(\"Realizando la concatenación_3\")\n",
    "df_concat = pd.concat(data_frames_3)\n",
    "print(\"Paso la concatenación_3\")\n",
    "df_concat = df_concat.sort_values('ID',ascending=True)\n",
    "t = Table.from_pandas(df_concat)\n",
    "t.write(f'Catalogos_finales/Catalogos_explode/catalogo_final_{run}_3.fits', overwrite=True)\n",
    "   \n",
    "print(\"Realizando la concatenación_4\")\n",
    "df_concat = pd.concat(data_frames_4)\n",
    "print(\"Paso la concatenación_4\")\n",
    "df_concat = df_concat.sort_values('ID',ascending=True)\n",
    "t = Table.from_pandas(df_concat)\n",
    "t.write(f'Catalogos_finales/Catalogos_explode/catalogo_final_{run}_4.fits', overwrite=True)\n",
    "   \n",
    "print(\"Realizando la concatenación_5\")\n",
    "df_concat = pd.concat(data_frames_5)\n",
    "print(\"Paso la concatenación_5\")\n",
    "df_concat = df_concat.sort_values('ID',ascending=True)\n",
    "t = Table.from_pandas(df_concat)\n",
    "t.write(f'Catalogos_finales/Catalogos_explode/catalogo_final_{run}_5.fits', overwrite=True)\n",
    "\n",
    "print(\"Realizando la concatenación_total\")\n",
    "df_concat = pd.concat(data_frames)\n",
    "print(\"Paso la concatenación\")\n",
    "df_concat = df_concat.sort_values('ID',ascending=True)\n",
    "t = Table.from_pandas(df_concat)\n",
    "t.write(f'Catalogos_finales/catalogo_final_{run}.fits', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 ('rodripython')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "4637e8e1303770fd9917f23b8a45bf3851764ec4effd23f330c051ed735dc8b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
